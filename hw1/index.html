<!DOCTYPE html>
<html>

<head>
	<!-- MathJax 3 setup -->
	<script>
		MathJax = {
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				displayMath: [['$$', '$$'], ['\\[', '\\]']]
			}
		};
	</script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

	<!-- Include custom font -->
	<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">

	<style>
		h1 {
			text-align: center;
		}

		.container {
			margin: 0 auto;
			padding: 60px 8%;
		}

		figure {
			text-align: center;
		}

		img {
			display: inline-block;
		}

		body {
			font-family: 'Inter', sans-serif;
		}

		p {
			text-indent: 2em;
		}
	</style>
</head>

<body>
	<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names:Gavin Jiang</div>

		<br>

		Link to webpage:
		<a href="https://cal-cs184-student.github.io/hw-webpages-jiangpf2022/">
			https://cal-cs184-student.github.io/hw-webpages-jiangpf2022/
		</a>

		<br>

		Link to GitHub repository:
		<a href="https://github.com/cal-cs184-student/sp25-hw1-sss">
			https://github.com/cal-cs184-student/sp25-hw1-sss
		</a>

		<figure>
			<img src="lion.jpg" alt="Lion" style="width:50%" />
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
    We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
    -->

		<h2 style="color:red">Overview</h2>
		<p>Give a high-level overview of what you implemented in this homework. Think about what you've built as
			a whole. Share your thoughts on what interesting things you've learned from completing the homework.</p>

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<h3 style="color: blue;">Walk through how you rasterize triangles in your own words.</h3>
		<p>
			To rasterize a triangle correctly, we first need to determine the <b>orientation</b> of the triangle's
			vertices. This ensures that regardless of whether the vertices are specified in <b>clockwise</b> or
			<b>counterclockwise</b> order, the triangle is correctly rendered. We achieve this by computing the
			signed area of the triangle:
		</p>

		\[
		A = (x_1 - x_0) (y_2 - y_0) - (y_1 - y_0) (x_2 - x_0)
		\]

		<p>
			If \( A < 0 \), the triangle is specified in a clockwise order, and we swap two vertices to make it
				counterclockwise. This standardizes the calculations and ensures proper filling. </p>

				<p>
					Next, we determine the <b>direction of the three edges</b> by computing their differences:
				</p>

				\[
				dx_0 = x_1 - x_0, \quad dy_0 = y_1 - y_0
				\]

				\[
				dx_1 = x_2 - x_1, \quad dy_1 = y_2 - y_1
				\]

				\[
				dx_2 = x_0 - x_2, \quad dy_2 = y_0 - y_2
				\]

				<p>
					To optimize rasterization, we compute the <b>bounding box</b> of the triangle. Instead of checking
					every pixel in the entire image, we only check the pixels within this bounding box:
				</p>

				\[
				x_{\text{min}} = \lfloor \min(x_0, x_1, x_2) \rfloor, \quad x_{\text{max}} = \lceil \max(x_0, x_1, x_2)
				\rceil
				\]
				\[
				y_{\text{min}} = \lfloor \min(y_0, y_1, y_2) \rfloor, \quad y_{\text{max}} = \lceil \max(y_0, y_1, y_2)
				\rceil
				\]

				<p>
					For each pixel \((x, y)\) within this bounding box, we use the <b>point-in-triangle test</b> based
					on edge equations:
				</p>

				\[
				L_i (x, y) = –(x - X_i) dY_i + (y - Y_i) dX_i
				\]

				<p>
					This can also be rewritten in the form:
				</p>

				\[
				L_i (x, y) = A_i x + B_i y + C_i
				\]

				<p>
					For each pixel at <b>center position</b> \( (x+0.5, y+0.5) \), we compute \( L_1, L_2, L_3 \). If
					all three satisfy:
				</p>

				\[
				L_1 \geq 0, \quad L_2 \geq 0, \quad L_3 \geq 0
				\]

				<p>
					then the pixel is inside the triangle, and we call the <code>fill_pixel(x, y, color)</code> function
					to color it.
				</p>

				<h3 style="color: blue;">
					Explain how your algorithm is no worse than one that checks each sample within the bounding box of
					the triangle. The bounding box of the triangle is defined as the smallest rectangle that can be
					drawn
					whilst ensuring that the entire triangle is within it.
				</h3>

				<p>
					To optimize the rasterization process, my algorithm first determines the <b>bounding box</b> of
					the triangle before iterating over pixels. The bounding box is calculated as:
				</p>

				\[
				x_{\text{min}} = \lfloor \min(x_0, x_1, x_2) \rfloor, \quad x_{\text{max}} = \lceil \max(x_0, x_1, x_2)
				\rceil
				\]
				\[
				y_{\text{min}} = \lfloor \min(y_0, y_1, y_2) \rfloor, \quad y_{\text{max}} = \lceil \max(y_0, y_1, y_2)
				\rceil
				\]

				<p>
					This ensures that the algorithm only considers the smallest rectangular region containing the
					triangle, avoiding unnecessary computations outside of this area. By limiting the loop to iterate
					within this bounding box, the number of pixels checked is at most the number of pixels in the
					bounding box.
				</p>

				<p>
					Since the bounding box is the minimal enclosing rectangle for the triangle, any algorithm that
					checks each sample within the bounding box will inherently examine at least the same number of
					pixels. My approach does not perform any additional operations beyond this predefined region,
					ensuring that it is <b>no worse</b> than a naïve method that simply iterates over all pixels within
					the bounding box.
				</p>

				<h3 style="color: blue;">
					Show a png screenshot of basic/test4.svg with the default viewing parameters and with the pixel
					inspector
					centered on an interesting part of the scene.
				</h3>

				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/test3.png" width="400px" />
								<figcaption>test3.svg</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/test4.png" width="400px" />
								<figcaption>test4.svg</figcaption>
							</td>
						</tr>
						<tr>
							<td style="text-align: center;">
								<img src="image/test5.png" width="400px" />
								<figcaption>test5.svg</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/test6.png" width="400px" />
								<figcaption>test6.svg</figcaption>
							</td>
						</tr>
					</table>
				</div>

				<h3 style="color:blue">
					Extra credit: Explain any special optimizations you did beyond simple bounding box triangle
					rasterization,
					with a timing comparison table (we suggest using the c++ clock() function around the svg.draw()
					command in DrawRend::redraw() to compare millisecond timings with your various optimizations off and
					on)
				</h3>

				<h4>Optimizations Implemented</h4>

				<p>
					In this extra credit task, I optimized the triangle rasterization process beyond the simple
					bounding box method.
					The following key optimizations were implemented:
				</p>

				<ul>
					<li>
						<b>Incremental Edge Function Updates:</b> Instead of recalculating edge functions for each pixel
						independently,
						we initialize them once and use incremental updates. Moving right by one pixel only requires
						adding the edge’s
						<code>A</code> coefficient, and moving down a row only requires adding <code>B</code>.
					</li>
					<li>
						<b>Bounding Box Clipping:</b> The bounding box is computed and clipped to screen limits before
						iteration,
						reducing unnecessary condition checks inside the loops.
					</li>
					<li>
						<b>Early Termination on Empty Rows:</b> Once a valid pixel is found in a row, the loop continues
						scanning,
						but if no more valid pixels can exist (due to triangle shape), it breaks early, avoiding
						unnecessary calculations.
					</li>
					<li>
						<b>Memory Access Optimization:</b> By reducing redundant memory accesses inside the loop,
						the optimized version improves cache locality and execution efficiency.
					</li>
				</ul>
				<h4>Core Code Comparison</h4>

				<p>
					The following code snippets highlight the main differences between the naive and optimized
					implementations.
				</p>

				<table border="1" style="border-collapse: collapse; text-align: left; width: 100%;">
					<tr>
						<th style="width: 50%; background-color: #f8d7da;">Naive Implementation</th>
						<th style="width: 50%; background-color: #d4edda;">Optimized Implementation</th>
					</tr>
					<tr>
						<td>
							<pre style="white-space: pre-wrap; font-size: 14px;">
// Loop over every pixel in bounding box
for(float i=x_min; i<=x_max; i++){
    for(float j=y_min; j<=y_max; j++){
        float posx = i + 0.5, posy = j + 0.5;
        float L1 = -(posx-x0)*dy0 + (posy-y0)*dx0;
        float L2 = -(posx-x1)*dy1 + (posy-y1)*dx1;
        float L3 = -(posx-x2)*dy2 + (posy-y2)*dx2;
        if (L1 >= 0 && L2 >= 0 && L3 >= 0) {
            fill_pixel(i, j, color);
        }
    }
}
            </pre>
						</td>
						<td>
							<pre style="white-space: pre-wrap; font-size: 14px;">
// Compute initial edge function values at (x_min + 0.5, y_min)
float L1_row = A0 * (x_min + 0.5) + B0 * y_min + C0;
float L2_row = A1 * (x_min + 0.5) + B1 * y_min + C1;
float L3_row = A2 * (x_min + 0.5) + B2 * y_min + C2;

// Loop per scanline, update edge function incrementally
for(int y = y_min; y <= y_max; y++){
    float L1 = L1_row, L2 = L2_row, L3 = L3_row;
    bool is_valid = false;
    
    for(int x = x_min; x <= x_max; x++){
        if (L1 >= 0 && L2 >= 0 && L3 >= 0) {
            fill_pixel(x, y, color);
            is_valid = true;
        } else if (is_valid) break; // Stop early
        L1 += A0; L2 += A1; L3 += A2;
    }

    L1_row += B0;
    L2_row += B1;
    L3_row += B2;
}
            </pre>
						</td>
					</tr>
				</table>

				<h4>Timing Comparison</h4>

				<p>
					Below is a timing comparison between the naive rasterization method and the optimized version,
					recorded in microseconds (us). The tests were conducted on different test cases (test 3, 4, 5, and
					6).
				</p>

				<table border="1" style="border-collapse: collapse; text-align: center; width: 80%;">
					<tr>
						<th>Test Case</th>
						<th>Naive Rasterization Time (us)</th>
						<th>Optimized Rasterization Time (us)</th>
						<th>Speedup</th>
					</tr>
					<tr>
						<td>3</td>
						<td>13,625</td>
						<td>7,123</td>
						<td>1.91x</td>
					</tr>
					<tr>
						<td>4</td>
						<td>796</td>
						<td>641</td>
						<td>1.24x</td>
					</tr>
					<tr>
						<td>5</td>
						<td>2,500</td>
						<td>1,508</td>
						<td>1.66x</td>
					</tr>
					<tr>
						<td>6</td>
						<td>1486us</td>
						<td>832</td>
						<td>1.785x</td>
					</tr>
				</table>


				<h2>Task 2: Antialiasing by Supersampling</h2>
				<h3 style="color:blue">
					Walk through your supersampling algorithm and data structures. Why is supersampling useful? What
					modifications did you make to the rasterization pipeline in the process? Explain how you used
					supersampling to antialias your triangles.
				</h3>
				<h4>Supersampling Algorithm and Data Structures</h4>
				<p>
					In my supersampling implementation, I first perform a finer sampling within the bounding box of the
					triangle.
					Specifically, I sample using a <code>sqrt(samplerate) × sqrt(samplerate)</code> grid for each pixel,
					allowing for more precise subpixel coverage testing.
				</p>
				<p>
					To determine whether these finer sample points are inside the triangle, I reuse the code from the
					previous task,
					which checks whether a point lies within the triangle's boundaries. All valid sample points are then
					stored in the
					<code>Sample_buffer</code>, which maintains per-sample color data for each pixel.
				</p>
				<p>
					Finally, in the <code>resolve_to_framebuffer</code> step, I aggregate the samples by computing the
					average of all
					sampled colors within a pixel and then write the final color to the framebuffer. This averaging
					process ensures
					smoother transitions between edges and significantly reduces aliasing artifacts.
				</p>

				<h4>Why is Supersampling Useful?</h4>
				<p>
					By taking multiple samples per pixel and averaging them, we can
					more accurately
					approximate the coverage of geometric shapes within a pixel.
				</p>
				<p>
					The primary benefits of supersampling include:
				</p>
				<ul>
					<li><b>Reduced aliasing:</b> Jagged edges and pixelation artifacts are smoothed out by averaging
						multiple samples.</li>
					<li><b>Improved color transitions:</b> Gradual color changes are better represented, reducing abrupt
						transitions that make edges appear rough.</li>
					<li><b>More accurate representation:</b> Supersampling captures finer details of the scene that
						would otherwise be lost due to limited resolution.</li>
				</ul>
				<p>
					The main modification to the rasterization pipeline involved increasing the number of samples per
					pixel and storing
					them in a dedicated sample buffer before resolving them into the final framebuffer. This required
					additional
					memory and computational resources but resulted in a noticeable improvement in visual quality.
				</p>
				<h3 style="color:blue">
					Show png screenshots of basic/test4.svg with the default viewing parameters and sample rates 1, 4,
					and 16 to compare them side-by-side. Position the pixel inspector over an area that showcases the
					effect dramatically; for example, a very skinny triangle corner. Explain why these results are
					observed.
				</h3>
				<p>
					The images above demonstrate the effects of supersampling with sample rates of 1, 4, and 16. As the
					sample rate increases,
					the aliasing artifacts, such as jagged edges and pixelation, become significantly reduced. This
					improvement is particularly noticeable
					along the edges of the triangles, especially at very acute corners.
				</p>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/super_1.png" width="300px" />
								<figcaption>supersample rate:1</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/super_4.png" width="300px" />
								<figcaption>supersample rate:4</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/super_16.png" width="300px" />
								<figcaption>supersample rate:16</figcaption>
							</td>
						</tr>
						<tr>
							<td style="text-align: center;">
								<img src="image/super_1s.png" width="300px" />
								<figcaption>supersample rate:1</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/super_4s.png" width="300px" />
								<figcaption>supersample rate:4</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/super_16s.png" width="300px" />
								<figcaption>supersample rate:16</figcaption>
							</td>
						</tr>
					</table>
				</div>
				<p>
					At a sample rate of 1, only one sample per pixel is taken, leading to visible aliasing, particularly
					in regions where triangle edges
					intersect with pixel boundaries. At a sample rate of 4, the additional samples allow for a more
					accurate representation of subpixel
					coverage, leading to smoother edges. Finally, at a sample rate of 16, the transition between colors
					is even more gradual, effectively
					eliminating visible aliasing and providing a much cleaner visual output.
				</p>

				<h3 style="color:blue">
					Extra credit: If you implemented alternative antialiasing methods, describe them and include
					comparison pictures demonstrating the difference between your method and grid-based supersampling.

				</h3>

				<p>
					In addition to grid-based supersampling, I implemented jittered sampling as an alternative
					antialiasing method.
					Unlike uniform grid-based supersampling, which places samples at evenly spaced intervals within each
					pixel,
					jittered sampling perturbs the sample positions randomly within the pixel. This randomization helps
					to
					break up regular aliasing patterns that might still be visible with uniform supersampling.
				</p>
				<p>
					The comparison image below demonstrates the difference between 4x supersampling and 4x jittered
					sampling:
				</p>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/super_4s.png" width="300px" />
								<figcaption>supersampling rate:4</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/jitter_4s.png" width="300px" />
								<figcaption>jitter sampling rate:4</figcaption>
							</td>
						</tr>
					</table>
				</div>
				<p>
					As observed in the image, the left side, which uses regular supersampling, still exhibits some
					aliasing artifacts,
					particularly along thin triangle edges. The right side, which employs jittered sampling, produces
					smoother edges
					because the random sampling helps reduce structured aliasing and better approximates the true
					geometry.
				</p>
				<p>
					Jittered sampling is particularly beneficial for handling high-frequency patterns and thin objects,
					where
					regular supersampling may still struggle with aliasing artifacts due to its structured sample
					placement.
				</p>
				<h2>Task 3: Transforms</h2>
				<h3>Translation Matrix</h3>
				<p>
					The translation matrix moves a point \((x, y)\) by \((dx, dy)\) and is represented as:
				</p>
				<p>
					\[
					\begin{bmatrix}
					1 & 0 & dx \\
					0 & 1 & dy \\
					0 & 0 & 1
					\end{bmatrix}
					\]
				</p>
				<h3>Scaling Matrix</h3>
				<p>
					The scaling matrix scales a point by \((sx, sy)\) along the x and y axes and is given by:
				</p>
				<p>
					\[
					\begin{bmatrix}
					sx & 0 & 0 \\
					0 & sy & 0 \\
					0 & 0 & 1
					\end{bmatrix}
					\]
				</p>

				<h3>Rotation Matrix</h3>
				<p>
					The rotation matrix rotates a point counterclockwise by \( \theta \) degrees and is given by:
				</p>
				<p>
					\[
					\begin{bmatrix}
					\cos(\theta) & -\sin(\theta) & 0 \\
					\sin(\theta) & \cos(\theta) & 0 \\
					0 & 0 & 1
					\end{bmatrix}
					\]
				</p>

				<h3>result</h3>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/transformation1.png" width="800px" />
								<figcaption>supersampling rate:4</figcaption>
							</td>
						</tr>
					</table>
				</div>
				<h3>Updated Cubeman (my_robot.svg)</h3>
				<p>
					Using translation, scaling, and rotation operations, I created an updated version of
					<code>robot.svg</code> named <code>my_robot.svg</code>. The new cubeman is animated to appear as if
					he is waving. This was achieved by rotating his arm and slightly adjusting the proportions and
					colors.
				</p>
				<p>
					The rasterized result of my updated cubeman is shown below:
				</p>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/my_robots.png" width="800px" />
								<figcaption>Updated cubeman (waving animation)</figcaption>
							</td>
						</tr>
					</table>
				</div>

				<h3>Extra Feature: Viewport Rotation</h3>
				<p>
					I also added a new feature to the GUI that allows users to rotate the viewport using the 'Q' and 'E'
					keys. This modification enables users to dynamically adjust the orientation of the entire scene.
				</p>
				<p>
					The feature was implemented in the <code>keyboard_event</code> function as follows:
				</p>
				<pre>
case 'Q':
    svg_to_ndc[current_svg] = rotate(-5) * svg_to_ndc[current_svg];
    redraw();
    break;

case 'E':
    svg_to_ndc[current_svg] = rotate(5) * svg_to_ndc[current_svg];
    redraw();
    break;
</pre>
				<p>
					By applying a 3x3 rotation matrix to <code>svg_to_ndc</code>, this feature rotates all objects in
					the scene, giving the user control over the view orientation.
				</p>
				<p>
					The result of applying viewport rotation is shown below:
				</p>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/press_q.png" width="400px" />
								<figcaption>Viewport rotation applied using 'Q' keys</figcaption>
							</td>
							<td style="text-align: center;">
								<img src="image/press_e.png" width="400px" />
								<figcaption>Viewport rotation applied using 'E' keys</figcaption>
							</td>
						</tr>
					</table>
				</div>
				<h2>Task 4: Barycentric coordinates</h2>
				<h3 style="color:blue">
					Explain barycentric coordinates in your own words and use an image to aid you in your explanation.
					One idea is to use a svg file that plots a single triangle with one red, one green, and one blue
					vertex, which should produce a smoothly blended color triangle.
				</h3>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/baycentric_interpolation_triangle.png" width="800px" />
								<figcaption>Barycentric interpolated color triangle</figcaption>
							</td>
						</tr>
					</table>
				</div>
				<p>
					Barycentric coordinates provide a way to represent any point inside a triangle as a weighted
					combination of the triangle’s three vertices. Given a triangle with vertices \( A(x_A, y_A) \), \(
					B(x_B, y_B) \), and \( C(x_C, y_C) \), a point \( P(x, y) \) inside the triangle can be expressed
					as:
				</p>
				<p>
					\[
					P = \alpha A + \beta B + \gamma C,
					\]
				</p>
				<p>
					where \( \alpha, \beta, \gamma \) are the barycentric coordinates, satisfying \( \alpha + \beta +
					\gamma = 1 \). The formulas for computing these weights are:
				</p>
				<p>
					\[
					\alpha = \frac{-(x - x_B)(y_C - y_B) + (y - y_B)(x_C - x_B)}{-(x_A - x_B)(y_C - y_B) + (y_A -
					y_B)(x_C - x_B)}
					\]
				</p>
				<p>
					\[
					\beta = \frac{-(x - x_C)(y_A - y_C) + (y - y_C)(x_A - x_C)}{-(x_B - x_C)(y_A - y_C) + (y_B -
					y_C)(x_A - x_C)}
					\]
				</p>
				<p>
					\[
					\gamma = 1 - \alpha - \beta
					\]
				</p>

				<h3>Color Interpolation using Barycentric Coordinates</h3>
				<p>
					By assigning colors \( C_A, C_B, C_C \) to the three vertices, we can interpolate the color at any
					point \( P \) inside the triangle using the same weights:
				</p>
				<p>
					\[
					C_P = \alpha C_A + \beta C_B + \gamma C_C
					\]
				</p>
				<p>
					This allows smooth color gradients to be created within a triangle, blending colors based on the
					distances to each vertex.
				</p>

				<h3 style="color:blue">Show a png screenshot of svg/basic/test7.svg with default viewing parameters and
					sample rate 1. If you make any additional images with color gradients, include them.</h3>
				<p>
					To demonstrate barycentric coordinate-based color interpolation, I rendered an SVG file containing a
					circle with multiple colors. The result is a smoothly blended color wheel circle.
				</p>
				<div style="display: flex; flex-direction: column; align-items: center;">
					<table style="width: 100%; text-align: center; border-collapse: collapse;">
						<tr>
							<td style="text-align: center;">
								<img src="image/baycentric_interpolation.png" width="800px" />
								<figcaption>Barycentric interpolated color</figcaption>
							</td>
						</tr>
					</table>
				</div>


				<h2>Task 5: "Pixel sampling" for texture mapping</h2>
				<h3 style="color:blue">Explain pixel sampling in your own words and describe how you implemented it to
					perform texture mapping. Briefly discuss the two different pixel sampling methods, nearest and
					bilinear.</h3>
				<p>
					Pixel sampling is the process of retrieving color values from a texture image to apply onto a
					rendered object.
					In texture mapping, each screen-space pixel corresponds to a texture-space coordinate, and we must
					determine
					how to compute the final color for that pixel based on the underlying texture pixels (texels).
					The two main pixel sampling methods are:
				</p>

				<ul>
					<li><strong>Nearest-neighbor sampling</strong>: Selects the texel closest to the computed texture
						coordinate.
						This method is fast but can result in blocky artifacts when upscaling or aliasing effects when
						downscaling.</li>
					<li><strong>Bilinear interpolation</strong>: Uses the four closest texels around the computed
						texture coordinate
						and interpolates their colors based on distance. This results in a smoother appearance compared
						to nearest-neighbor sampling.</li>
				</ul>

				<p>
					In my implementation, I defined a <code>SampleParams</code> struct that includes a pixel sampling
					method (`psm`)
					and a texture coordinate (`p_uv`). When rendering textured triangles, I compute the barycentric
					interpolation
					of texture coordinates at each pixel and pass them to the <code>Texture::sample</code> function.
					Depending on
					whether `psm` is set to <code>P_NEAREST</code> or <code>P_LINEAR</code>, the `sample` function calls
					either
					`sample_nearest()` or `sample_bilinear()`, respectively.
				</p>

				<h3 style="color:blue">Check out the svg files in the svg/texmap/ directory. Use the pixel inspector to
					find a good example of where bilinear sampling clearly defeats nearest sampling. Show and compare
					four png screenshots using nearest sampling at 1 sample per pixel, nearest sampling at 16 samples
					per pixel, bilinear sampling at 1 sample per pixel, and bilinear sampling at 16 samples per pixel.
				</h3>

				<p>
					Below, I present four different renderings of the texture mapped image from <code>test1.svg</code>.
					The images
					compare the results of nearest and bilinear sampling at 1 sample per pixel (1 spp) and 16 samples
					per pixel (16 spp).
				</p>

				<table>
					<tr>
						<td><strong>Nearest, 1 spp</strong></td>
						<td><strong>Bilinear, 1 spp</strong></td>
					</tr>
					<tr>
						<td><img src="image/map_nearest_1.png" alt="Nearest, 1 spp" width="400"></td>
						<td><img src="image/map_bilinear_1.png" alt="Bilinear, 1 spp" width="400"></td>
					</tr>
					<tr>
						<td><strong>Nearest, 16 spp</strong></td>
						<td><strong>Bilinear, 16 spp</strong></td>
					</tr>
					<tr>
						<td><img src="image/map_nearest_16.png" alt="Nearest, 16 spp" width="400"></td>
						<td><img src="image/map_bilinear_16.png" alt="Bilinear, 16 spp" width="400"></td>
					</tr>
				</table>

				<h3>Detailed Close-ups</h3>

				<p>
					To better illustrate the differences, we provide zoomed-in sections of the texture-mapped images.
				</p>

				<table>
					<tr>
						<td><strong>Nearest, 1 spp (Detail)</strong></td>
						<td><strong>Bilinear, 1 spp (Detail)</strong></td>
					</tr>
					<tr>
						<td><img src="image/map_nearst_1_detail.png" alt="Nearest, 1 spp Detail" width="400"></td>
						<td><img src="image/map_bilinear_1_detail.png" alt="Bilinear, 1 spp Detail" width="400"></td>
					</tr>
					<tr>
						<td><strong>Nearest, 16 spp (Detail)</strong></td>
						<td><strong>Bilinear, 16 spp (Detail)</strong></td>
					</tr>
					<tr>
						<td><img src="image/map_nearest_16_detail.png" alt="Nearest, 16 spp Detail" width="400"></td>
						<td><img src="image/map_bilinear_16_detail.png" alt="Bilinear, 16 spp Detail" width="400"></td>
					</tr>
				</table>

				<h3 style="color:blue">Comment on the relative differences. Discuss when there will be a large
					difference between the two methods and why.</h3>

				<h3 style="color:blue">Comment on the relative differences. Discuss when there will be a large
					difference between the two methods and why.</h3>

				<p>
					The differences between <b>nearest-neighbor</b> and <b>bilinear sampling</b> are most evident in the
					close-up images.
					Nearest-neighbor sampling exhibits blocky artifacts, especially when a texture is magnified, as each
					texel is assigned to a single pixel without interpolation.
					This results in noticeable pixelation and jagged edges, particularly along diagonal lines or
					high-contrast transitions.
					Bilinear sampling, on the other hand, reduces these artifacts by averaging the colors of the four
					nearest texels, producing a much smoother and more visually appealing transition between colors.
				</p>

				<p>
					The effect of increasing the sample rate from 1 sample per pixel to 16 samples per pixel is also
					significant.
					At a higher sample rate, aliasing is reduced in both methods, but nearest-neighbor sampling still
					retains its characteristic blocky appearance due to the lack of interpolation.
					Bilinear sampling combined with supersampling provides the smoothest results, as it not only
					interpolates texel values but also benefits from multiple sample points per pixel, further reducing
					jagged edges and improving texture fidelity.
				</p>

				<p>
					The difference between these two methods is most pronounced in cases where textures undergo
					significant magnification, as nearest-neighbor sampling causes visible pixelation while bilinear
					interpolation produces a smoother result.
					In minification scenarios, where a high-resolution texture is displayed at a smaller size, aliasing
					artifacts appear in nearest-neighbor sampling due to the loss of high-frequency details, while
					bilinear filtering reduces these effects but can introduce blurring.
					Additionally, when a texture contains fine details, such as text or intricate patterns,
					nearest-neighbor sampling fails to preserve the smoothness of the original texture, leading to sharp
					discontinuities, whereas bilinear filtering maintains a more natural transition between colors.
					However, in cases where sharp edges are intentionally desired or when performance constraints are
					critical, nearest-neighbor sampling remains a viable choice due to its simplicity and efficiency.
				</p>


				<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
				<p>
					In texture mapping, level sampling (mipmap selection) plays a crucial role in determining the
					trade-off between texture quality, aliasing reduction, memory usage, and rendering speed. By using
					mipmaps, we can sample lower-resolution textures for distant objects, reducing aliasing and
					improving performance.
				</p>

				<h3>Tradeoffs between speed, memory usage, and antialiasing power</h3>
				<p>
					The three main factors influencing texture sampling—speed, memory usage, and antialiasing
					effectiveness—are interconnected. Nearest sampling is the fastest but produces blocky, aliased
					results. Bilinear filtering smooths the texture at a minor performance cost. When combined with
					mipmaps, bilinear filtering can significantly improve texture quality while maintaining efficient
					memory usage. Higher mipmap levels reduce aliasing but increase memory consumption. Trilinear
					filtering (L_LINEAR with P_LINEAR) further improves smooth transitions between mipmap levels at the
					cost of extra computation.
				</p>

				<h3>Comparison of Different Sampling Techniques</h3>
				<p>
					Below, we present four images, each corresponding to a different combination of level and pixel
					sampling:
				</p>

				<ul>
					<li><strong>L_ZERO and P_NEAREST:</strong> Samples only from the base mipmap level using nearest
						neighbor interpolation, leading to severe aliasing.</li>
					<li><strong>L_ZERO and P_LINEAR:</strong> Samples from the base level but interpolates between
						texels, slightly reducing aliasing.</li>
					<li><strong>L_NEAREST and P_NEAREST:</strong> Selects the nearest appropriate mipmap level but still
						uses nearest sampling, improving aliasing slightly.</li>
					<li><strong>L_LINEAR and P_LINEAR:</strong> Uses trilinear filtering, blending between mipmap levels
						and interpolating pixels, producing the smoothest and highest quality texture.</li>
				</ul>

				<div style="display: flex; flex-wrap: wrap; justify-content: center;">
					<div style="margin: 10px; text-align: center;">
						<img src="image/l_zero_p_nearest.png" alt="L_ZERO P_NEAREST" width="400">
						<p>L_ZERO & P_NEAREST</p>
					</div>
					<div style="margin: 10px; text-align: center;">
						<img src="image/l_zero_p_linear.png" alt="L_ZERO P_LINEAR" width="400">
						<p>L_ZERO & P_LINEAR</p>
					</div>
					<div style="margin: 10px; text-align: center;">
						<img src="image/l_linear_p_nearest.png" alt="L_NEAREST P_NEAREST" width="400">
						<p>L_NEAREST & P_NEAREST</p>
					</div>
					<div style="margin: 10px; text-align: center;">
						<img src="image/l_linear_p_linear.png" alt="L_LINEAR P_LINEAR" width="400">
						<p>L_LINEAR & P_LINEAR</p>
					</div>
				</div>

				<h3>Discussion on the Differences</h3>
				<p>
					The choice of sampling method has a significant impact on visual quality. The L_ZERO & P_NEAREST
					method results in severe pixelation and aliasing due to the lack of interpolation. L_ZERO & P_LINEAR
					improves this by interpolating between texels, creating a smoother but still aliased result.
					L_NEAREST & P_NEAREST benefits from mipmap level selection, reducing aliasing, but still suffers
					from blocky artifacts due to nearest neighbor interpolation. The best results are achieved with
					L_LINEAR & P_LINEAR, which combines both mipmap interpolation and bilinear filtering, providing the
					smoothest texture transitions with minimal aliasing.
				</p>
				<p>
					In general, level sampling (L_NEAREST or L_LINEAR) is particularly beneficial when a texture
					undergoes significant minification (i.e., when a high-resolution texture is projected onto a small
					screen area). This prevents aliasing and shimmering effects. However, increasing the level sampling
					complexity introduces additional computational costs, making it a trade-off between quality and
					performance.
				</p>


				<h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
				<p>
					Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore
					et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut
					aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
					cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
					culpa qui officia deserunt mollit anim id est laborum.
				</p>
				<!-- End tasks -->
	</div>
</body>

</html>