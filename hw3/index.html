<html>

<head>
	<!-- MathJax 3 setup -->
	<script>
		MathJax = {
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				displayMath: [['$$', '$$'], ['\\[', '\\]']]
			}
		};
	</script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

	<!-- Include custom font -->
	<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">

	<style>
		h1 {
			text-align: center;
		}

		.container {
			margin: 0 auto;
			padding: 60px 8%;
		}

		figure {
			text-align: center;
		}

		img {
			display: inline-block;
		}

		body {
			font-family: 'Inter', sans-serif;
		}

		p {
			text-indent: 2em;
		}
	</style>
</head>

<body>
	<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: </div>

		<br>

		Link to webpage: <a
			href="https://cal-cs184-student.github.io/hw-webpages-jiangpf2022/">https://cal-cs184-student.github.io/hw-webpages-jiangpf2022/</a>
		Link to GitHub repository: <a
			href="https://github.com/cal-cs184-student/sp25-hw3-spring-break">https://github.com/cal-cs184-student/sp25-hw3-spring-break</a>

		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%" />
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p>
			In this homework, I implemented a comprehensive ray-tracing pipeline, covering essential rendering
			components from basic ray generation and intersection testing to advanced global illumination techniques. I
			began by developing efficient intersection algorithms for geometric primitives like triangles and spheres.
			To significantly enhance performance, I constructed a Bounding Volume Hierarchy (BVH) using a
			midpoint-splitting heuristic, achieving remarkable speedups for complex scenes. I explored direct
			illumination through both uniform hemisphere sampling and importance sampling strategies, clearly
			demonstrating the latter’s superior effectiveness in reducing noise and enhancing realism. Further, I
			extended the renderer to handle indirect illumination via recursive ray tracing, incorporating Russian
			Roulette termination to balance accuracy and computational efficiency. Lastly, I implemented adaptive
			sampling, dynamically allocating rendering resources based on pixel variance, dramatically optimizing
			rendering time without sacrificing image quality.

			This project deepened my understanding of realistic lighting simulation and highlighted the importance of
			algorithmic optimization in rendering workflows. The striking visual difference between direct and indirect
			illumination, especially subtle effects like color bleeding and realistic soft shadows, was particularly
			fascinating. Overall, this homework strengthened my grasp of core ray-tracing techniques and their practical
			application in generating photorealistic imagery.
		</p>



		<h2>Part 1: Ray Generation and Scene Intersection</h2>


		<h3 style="color:blue">Walk through the ray generation and primitive intersection parts of the rendering
			pipeline.</h3>
		<p>The rendering pipeline starts with generating camera rays that pass through the virtual sensor plane and then
			intersect with scene primitives such as triangles and spheres. The process involves the following steps:</p>

		<h3>Ray Generation</h3>
		<p>The function <code>Camera::generate_ray(double x, double y)</code> generates a ray from the camera. Given
			normalized image coordinates \((x, y)\), the function maps them to the camera sensor plane, which is aligned
			with the \(Z = -1\) plane in camera space. The function follows these steps:</p>
		<ul>
			<li>Convert horizontal and vertical fields of view \(hFov\) and \(vFov\) from degrees to radians.</li>
			<li>Compute the sensor position corresponding to \((x, y)\) using the formula:
				\[
				x_{sensor} = (2x - 1) \tan\left(\frac{hFov}{2}\right), \quad y_{sensor} = (2y - 1)
				\tan\left(\frac{vFov}{2}\right), \quad z_{sensor} = -1
				\]
			</li>
			<li>Transform the ray direction from camera space to world space using the camera-to-world matrix \(c2w\).
			</li>
			<li>Normalize the ray direction and return a ray starting at the camera position.</li>
		</ul>

		<h3>Primitive Intersection</h3>
		<p>Once rays are generated, they are tested for intersections with scene primitives. The intersection tests for
			triangles and spheres are explained below:</p>

		<h4>Triangle Intersection</h4>
		<p>We implement the Möller–Trumbore algorithm for ray-triangle intersections. Key steps include:</p>
		<ul>
			<li>Compute edge vectors:
				\[
				e_1 = p_2 - p_1, \quad e_2 = p_3 - p_1
				\]
			</li>
			<li>Compute the normal vector and denominator:
				\[
				N = e_1 \times e_2, \quad d_N = \mathbf{r.d} \cdot N
				\]
			</li>
			<li>Calculate intersection parameter \(t\):
				\[
				t = \frac{(p_1 - \mathbf{r.o}) \cdot N}{d_N}
				\]
				Verify \(t\) is within \(min_t\) and \(max_t\).
			</li>
			<li>Calculate barycentric coordinates:
				\[
				\alpha = \frac{\|(p_2 - P) \times (p_3 - P)\|}{\|N\|}, \quad
				\beta = \frac{\|(p_1 - P) \times (p_3 - P)\|}{\|N\|}, \quad
				\gamma = \frac{\|(p_1 - P) \times (p_2 - P)\|}{\|N\|}
				\]
				Intersection occurs if \(\alpha + \beta + \gamma \approx 1\).
			</li>
			<li>Update intersection data accordingly.</li>
		</ul>

		<h4>Sphere Intersection</h4>
		<p>The ray-sphere intersection test solves the quadratic equation formed by substituting the ray equation into
			the sphere equation. Steps include:</p>
		<ul>
			<li>Compute vector from ray origin to sphere center:
				\[
				\mathbf{oc} = \mathbf{r.o} - \mathbf{o}
				\]
			</li>
			<li>Calculate coefficients:
				\[
				a = \mathbf{r.d} \cdot \mathbf{r.d}, \quad b = 2(\mathbf{oc} \cdot \mathbf{r.d}), \quad c = \mathbf{oc}
				\cdot \mathbf{oc} - r^2
				\]
			</li>
			<li>Determine discriminant \(\Delta = b^2 - 4ac\). Intersection exists only if \(\Delta \geq 0\).</li>
			<li>If \(\Delta \geq 0\), compute intersection points:
				\[
				t_{1,2} = \frac{-b \pm \sqrt{\Delta}}{2a}
				\]
			</li>
			<li>Select the valid intersection within ray bounds, update intersection structure.</li>
		</ul>

		<h3 style="color:blue">Explain the triangle intersection algorithm you implemented in your own words.</h3>
		<p>The implemented algorithm is based on the Möller–Trumbore method:</p>
		<ul>
			<li>Calculate two triangle edges, \(e_1\) and \(e_2\).</li>
			<li>Compute the triangle's normal vector \(N\).</li>
			<li>Find intersection parameter \(t\) using ray and normal vector.</li>
			<li>Use barycentric coordinates to verify the intersection within triangle boundaries.</li>
			<li>If valid, update intersection details.</li>
		</ul>

		<h3 style="color:blue">Show images with normal shading for a few small .dae files.</h3>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q1-1.png" width="300px" />
						<figcaption>CBsphere</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q1-2.png" width="300px" />
						<figcaption>CBgems</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q1-3.png" width="300px" />
						<figcaption>bunny</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q1-4.png" width="300px" />
						<figcaption>CBlucy</figcaption>
					</td>
				</tr>
			</table>
		</div>




		<h2>Part 2: Bounding Volume Hierarchy</h2>

		<h3 style="color:blue">Walk through your BVH construction algorithm. Explain the heuristic you chose for picking
			the splitting point.</h3>
		<p>The BVH construction algorithm operates recursively. Initially, a bounding box is computed that contains all
			primitives. If the number of primitives is below or equal to the maximum leaf size, the node becomes a leaf.
			Otherwise, the algorithm selects an axis based on the bounding box's largest dimension (x, y, or z).
			Specifically, it computes the extent along each axis and chooses the axis with the greatest length:
			\[
			\text{axis} = \arg\max_{\text{x,y,z}}(\text{extent}_x, \text{extent}_y, \text{extent}_z)
			\]
			Then, it determines the splitting point at the midpoint of this axis:
			\[
			\text{split_pos} = \frac{\text{bbox.min[axis]} + \text{bbox.max[axis]}}{2}
			\]
			Primitives are divided into left and right subsets based on whether their centroid lies to the left or right
			of this split position. This splitting continues recursively, efficiently organizing primitives into a
			hierarchy.
		</p>

		<h3 style="color:blue">Show images with normal shading for a few large .dae files.</h3>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q2-1.png" width="300px" />
						<figcaption>Maxplanck</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q1-4.png" width="300px" />
						<figcaption>CBluncy</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q2-2.png" width="300px" />
						<figcaption>beast</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q2-3.png" width="300px" />
						<figcaption>Peter</figcaption>
					</td>
				</tr>
			</table>
		</div>

		<h3 style="color:blue">Compare rendering times on a few scenes with moderately complex geometries with and
			without BVH acceleration. Present your results in a one-paragraph analysis.</h3>

		<table style="width:60%; margin:auto; border-collapse: collapse; text-align:center;">
			<tr>
				<th style="border:1px solid black;">Scene</th>
				<th style="border:1px solid black;">With BVH (s)</th>
				<th style="border:1px solid black;">Without BVH (s)</th>
			</tr>
			<tr>
				<td style="border:1px solid black;">maxplanck</td>
				<td style="border:1px solid black;">0.0870</td>
				<td style="border:1px solid black;">40.4940</td>
			</tr>
			<tr>
				<td style="border:1px solid black;">CBlucy</td>
				<td style="border:1px solid black;">0.1030</td>
				<td style="border:1px solid black;">465.3408</td>
			</tr>
			<tr>
				<td style="border:1px solid black;">beast</td>
				<td style="border:1px solid black;">0.0777</td>
				<td style="border:1px solid black;">69.9438</td>
			</tr>
			<tr>
				<td style="border:1px solid black;">Peter</td>
				<td style="border:1px solid black;">0.0708</td>
				<td style="border:1px solid black;">31.6934</td>
			</tr>
		</table>

		<p>The performance improvements with BVH acceleration are dramatic. For instance, the scene "CBlucy," which took
			465.3408 seconds without BVH, reduced dramatically to only 0.1030 seconds with BVH. Similar improvements are
			observed in other scenes such as "maxplanck," "beast," and "Peter." These results clearly demonstrate the
			significant computational advantage provided by BVH acceleration, transforming intersection complexity from
			linear to logarithmic, which greatly enhances rendering efficiency and feasibility for complex geometries.
		</p>


		<h2>Part 3: Direct Illumination</h2>

		<h3 style="color:blue">Walk through both implementations of the direct lighting function.</h3>

		<h4>(1) Uniform Hemisphere Sampling</h4>
		<p>
			This method uniformly samples incoming directions on a hemisphere around the intersection point. For each
			direction, it casts a ray and checks intersection with light sources. Its contribution is computed using the
			reflectance equation:
		</p>
		\[
		L_{out}(p, w_o) \approx \frac{1}{N}\sum_{i=1}^{N}f(w_o, w_i)L_i \cos\theta_i\frac{2\pi}{pdf}
		\]

		<h4>(2) Importance Sampling Lights</h4>
		<p>
			This approach samples directly from the light sources, significantly reducing variance. Rays are cast
			specifically towards lights, and radiance contributions are calculated only when rays are unobstructed:
		</p>
		\[
		L_{out}(p, w_o) \approx \sum_{lights}\frac{1}{N}\sum_{i=1}^{N}\frac{f(w_o, w_i)L_i\cos\theta_i}{pdf}
		\]

		<h3 style="color:blue">Show images rendered with both implementations of the direct lighting function.</h3>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q3-1.png" width="300px" />
						<figcaption>Uniform Hemisphere Sampling</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q3-2.png" width="300px" />
						<figcaption>Importance Sampling Lights</figcaption>
					</td>
				</tr>
			</table>
		</div>

		<h3 style="color:blue">Compare the noise levels in soft shadows (1 sample per pixel).</h3>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q3-3.png" width="300px" />
						<figcaption>1 Light Ray</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q3-4.png" width="300px" />
						<figcaption>4 Light Rays</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q3-5.png" width="300px" />
						<figcaption>16 Light Rays</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q3-6.png" width="300px" />
						<figcaption>64 Light Rays</figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p>
			Increasing the number of light rays significantly reduces the noise in the shadows. With fewer samples, the
			shadows exhibit substantial noise, while higher sample counts yield smoother, more realistic results.
		</p>

		<h3 style="color:blue">Comparison between uniform hemisphere sampling and lighting sampling.</h3>
		<p>
			Importance sampling lights dramatically outperforms uniform hemisphere sampling because it explicitly
			samples rays directed towards actual light sources, thus significantly reducing variance and noise. Uniform
			hemisphere sampling randomly selects rays across the entire hemisphere, many of which do not contribute
			meaningful illumination, resulting in slower convergence and noticeable grainy artifacts in the shadows. In
			contrast, importance sampling ensures that computational resources focus on directions that truly affect
			illumination, providing faster convergence, smoother soft shadows, and higher-quality, realistic renderings,
			especially in scenes with complex lighting.
		</p>



		<h2>Part 4: Global Illumination</h2>

		<h3 style="color:blue">Walk through your implementation of the indirect lighting function.</h3>
		<p>
			In my implementation, the function <code>at_least_one_bounce_radiance</code> recursively traces rays to
			calculate indirect lighting. At each intersection point, I first calculate direct lighting using
			<code>one_bounce_radiance</code>. If the maximum ray depth has not yet been reached, I sample a new incoming
			direction based on the surface's diffuse BSDF using <code>sample_f</code>, which returns both the sampled
			direction and its probability density function (PDF). I then cast a new ray from the intersection point in
			this sampled direction. If the ray intersects another object, I recursively compute the indirect radiance
			from that new intersection point, accumulating the result. Additionally, I implemented Russian Roulette
			termination with a probability of 0.35 after at least one bounce to prevent unnecessary computation of
			insignificant paths while ensuring unbiased results.
		</p>

		<h3 style="color:blue">Show some images rendered with global (direct and indirect) illumination. Use 1024
			samples per pixel.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/Q4-1.png" width="300px" />
						<figcaption>CBunny</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/Q3-4.png" width="300px" />
						<figcaption>4 Light Rays</figcaption>
					</td>
				</tr>
			</table>
		</div>

		<h3 style="color:blue">Pick one scene and compare rendered views first with only direct illumination, then only
			indirect illumination. Use 1024 samples per pixel.</h3>
		<div style="display:flex;">
			<div style="margin-right:10px;">
				<img src="image/CBbunny_only_direct.png" width="300px">
				<figcaption><strong>Direct Illumination Only</strong></figcaption>
			</div>
			<div>
				<img src="image/CBbunny_only_indirect.png" width="300px">
				<figcaption><strong>Indirect Illumination Only</strong></figcaption>
			</div>
		</div>
		<p>
			From these images, we can clearly see the distinction between direct and indirect illumination. The direct
			illumination image shows only the area directly facing the light source (in this case, the ceiling light),
			resulting in a very limited and starkly contrasted lighting situation with the rest of the scene completely
			dark. In contrast, the indirect illumination image vividly illustrates how light bounces off surfaces,
			creating soft shadows, gentle gradients, and noticeable color bleeding—such as the red and blue hues
			reflecting from the walls onto the bunny and surrounding surfaces. This demonstrates the significant
			contribution of indirect illumination to realistic rendering, emphasizing the importance of capturing
			bounced lighting effects to achieve visually convincing results.
		</p>

		<h3 style="color:blue">For CBbunny.dae, render the mth bounce of light with max_ray_depth set to 0, 1, 2, 3, 4,
			and 5 (the -m flag), and isAccumBounces=false. Explain in your write-up what you see for the 2nd and 3rd
			bounce of light, and how it contributes to the quality of the rendered image compared to rasterization. Use
			1024 samples per pixel.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_000.png" width="300px" />
						<figcaption>max_ray_depth:0</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_111.png" width="300px" />
						<figcaption>max_ray_depth:1</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_222.png" width="300px" />
						<figcaption>max_ray_depth:2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_333.png" width="300px" />
						<figcaption>max_ray_depth:3</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_444.png" width="300px" />
						<figcaption>max_ray_depth:4</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_555.png" width="300px" />
						<figcaption>max_ray_depth:5</figcaption>
					</td>
				</tr>
			</table>
		</div>
		<p>
			The 2nd bounce of light shows subtle yet essential indirect illumination effects, notably color bleeding,
			where colors from the walls softly illuminate adjacent surfaces. This contributes greatly to the realism by
			enriching the visual complexity beyond direct lighting alone. In the 3rd bounce, the effect becomes even
			subtler, with faint lighting contributions providing additional depth and nuanced shading to shadowed areas.
			Compared to rasterization—which typically captures only direct illumination—these additional bounces
			significantly enhance realism, capturing how light behaves naturally, reflecting and diffusing within the
			scene environment to produce visually richer and more lifelike results.
		</p>

		<h3 style="color:blue">Compare rendered views of accumulated and unaccumulated bounces for CBbunny.dae with
			max_ray_depth set to 0, 1, 2, 3, 4, and 5 (the -m flag). Use 1024 samples per pixel.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_0000.png" width="300px" />
						<figcaption>max_ray_depth:0(accumulated)</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_1111.png" width="300px" />
						<figcaption>max_ray_depth:1(accumulated)</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_2222.png" width="300px" />
						<figcaption>max_ray_depth:2(accumulated)</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_3333.png" width="300px" />
						<figcaption>max_ray_depth:3(accumulated)</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_4444.png" width="300px" />
						<figcaption>max_ray_depth:4(accumulated)</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_5555.png" width="300px" />
						<figcaption>max_ray_depth:5(accumulated)</figcaption>
					</td>
				</tr>
			</table>
		</div>
		<p>
			Accumulated rendering incorporates all previous bounce contributions, leading to increasingly realistic
			illumination as depth increases. Unaccumulated views isolate each bounce's individual lighting contribution,
			clearly illustrating how each additional bounce progressively enriches the overall visual quality and
			realism of the scene.
		</p>

		<h3 style="color:blue">For CBbunny.dae, output the Russian Roulette rendering with max_ray_depth set to 0, 1, 2,
			3, 4, and 100 (the -m flag). Use 1024 samples per pixel.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_0_0_R.png" width="300px" />
						<figcaption>max_ray_depth:0</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_1_0_R.png" width="300px" />
						<figcaption>max_ray_depth:1</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_2_0_R.png" width="300px" />
						<figcaption>max_ray_depth:2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_3_0_R.png" width="300px" />
						<figcaption>max_ray_depth:3</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_4_0_R.png" width="300px" />
						<figcaption>max_ray_depth:4</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_100_0_R.png" width="300px" />
						<figcaption>max_ray_depth:100</figcaption>
					</td>
				</tr>
			</table>
		</div>
		<p>
			Russian Roulette allows unbiased termination of low-contribution paths, significantly improving rendering
			efficiency. With a higher maximum depth (e.g., 100), the rendering results converge smoothly without much
			difference beyond a certain bounce count, demonstrating diminishing visual returns at higher bounce counts.
		</p>

		<h3 style="color:blue">Pick one scene and compare rendered views with various sample-per-pixel rates, including
			at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.</h3>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_1_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:1</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_2_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:2</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_4_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:4</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_8_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:8</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_16_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:16</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_64_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:64</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_1024_S.png" width="300px" />
						<figcaption>sample-per-pixel rates:1024</figcaption>
					</td>
				</tr>
			</table>
		</div>
		<p>
			Lower sampling rates result in visibly noisy images due to fewer samples capturing lighting variability. As
			the sample-per-pixel count increases, the noise decreases progressively, and illumination becomes smoother
			and more accurate, highlighting the importance of adequate sampling for high-quality rendering.
		</p>


		<h2>Part 5: Adaptive Sampling</h2>

		<h3 style="color:blue">Explain adaptive sampling. Walk through your implementation of adaptive sampling.</h3>
		<p>
			Adaptive sampling optimizes rendering by dynamically allocating more samples to regions requiring more
			attention—those with high variance—and fewer samples to regions with less complexity. Instead of uniformly
			sampling every pixel to a fixed high rate, adaptive sampling evaluates convergence at each pixel based on
			statistical confidence intervals. Specifically, we calculate the illuminance mean (μ) and variance (σ²) for
			each pixel and determine a convergence interval (I). If <code>I ≤ maxTolerance × μ</code>, we assume
			convergence and cease further sampling of that pixel. My implementation keeps running totals of pixel
			illuminance (s1) and squared illuminance (s2), allowing efficient computation of μ and σ² after each batch
			of samples (<code>samplesPerBatch</code>). We repeat this process until either the convergence criterion is
			met or the maximum samples per pixel limit is reached.
		</p>

		<h3 style="color:blue">Pick two scenes and render them with at least 2048 samples per pixel. Show a good
			sampling rate image with clearly visible differences in sampling rate over various regions and pixels.
			Include both your sample rate image, which shows how your adaptive sampling changes depending on which part
			of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5
			for max ray depth.</h3>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
						<img src="Image/CBbunny_A.png" width="300px" />
						<figcaption>max_ray_depth:0</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/CBbunny_A_rate.png" width="300px" />
						<figcaption>max_ray_depth:1</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
						<img src="Image/sphere_A.png" width="300px" />
						<figcaption>max_ray_depth:2</figcaption>
					</td>
					<td style="text-align: center;">
						<img src="Image/sphere_A_rate.png" width="300px" />
						<figcaption>max_ray_depth:3</figcaption>
					</td>
				</tr>
			</table>
		</div>

		<p>
			The adaptive sampling visualizations clearly illustrate how sampling effort dynamically varies across image
			regions. High-variance areas, such as edges, shadows, and points of indirect lighting reflection, are
			highlighted in red, indicating higher sample counts to achieve noise-free rendering. In contrast, regions
			with more uniform illumination are shown in blue, signifying fewer samples are needed for convergence. This
			adaptive strategy efficiently reduces computation time by allocating rendering resources primarily where
			they're needed most, resulting in high-quality images that are both realistic and computationally efficient.
		</p>



	</div>
</body>

</html>